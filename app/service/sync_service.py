import pandas as pd
import os
from datetime import datetime, timedelta
from app.service.vector_service import VectorService
from app.core.logger import logger

class SyncService:
    """
    íŠ¹ì • í˜•ì‹ì˜ íŠ¸ë Œë“œ ë¶„ì„ CSV íŒŒì¼ì„ Vector DBì™€ ë™ê¸°í™”í•˜ëŠ” ì„œë¹„ìŠ¤
    - í—ˆìš© íŒŒì¼ëª…: (SNS)_(ì¹´í…Œê³ ë¦¬)_(ë‚ ì§œ)_7d_real_data_keyword_frequencies.csv
    - ì •ì±…: 30ì¼ ë³´ê´€, ë¹ˆë„ìˆ˜ 3 ì´ìƒ ì ì¬, Rank ì œì™¸
    """
    
    # í—ˆìš©í•  íŒŒì¼ëª…ì˜ ì ‘ë¯¸ì‚¬ (Suffix) ì •ì˜
    REQUIRED_SUFFIX = "_30d_real_data_keyword_frequencies.csv"

    def __init__(self, vector_service: VectorService):
        self.vector_service = vector_service

    def sync_csv_to_db(self, file_path: str):
        """ì§€ì •í•œ íŒŒì¼ì˜ ì´ë¦„ í˜•ì‹ì„ ê²€ì¦í•˜ê³  ë°ì´í„°ë¥¼ DBì— ì ì¬í•©ë‹ˆë‹¤."""
        base_name = os.path.basename(file_path)

        # 1. íŒŒì¼ëª… ë’·ë¶€ë¶„(Suffix) ê²€ì¦
        if not base_name.endswith(self.REQUIRED_SUFFIX):
            logger.error(f"âŒ ê±´ë„ˆë¸œ: íŒŒì¼ í˜•ì‹ì´ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ({base_name})")
            logger.info(f"ğŸ’¡ í•„ìˆ˜ í˜•ì‹: [SNS]_[ì¹´í…Œê³ ë¦¬]_[ë‚ ì§œ]{self.REQUIRED_SUFFIX}")
            return

        # 2. íŒŒì¼ëª…ì—ì„œ ì •ë³´ ì¶”ì¶œ
        # ë’·ë¶€ë¶„ ì ‘ë¯¸ì‚¬ë¥¼ ì œê±°í•œ í›„ '_'ë¡œ ë¶„ë¦¬
        prefix = base_name.replace(self.REQUIRED_SUFFIX, "")
        parts = prefix.split("_")
        
        if len(parts) < 3:
            logger.error(f"âŒ íŒŒì¼ëª… ì •ë³´ ë¶€ì¡±: {base_name} (SNS, ì¹´í…Œê³ ë¦¬, ë‚ ì§œ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤)")
            return

        sns_name = parts[0]
        category = parts[1]
        file_date_str = parts[2]

        try:
            target_date = datetime.strptime(file_date_str, "%Y%m%d")
            # 30ì¼ ë³´ê´€ ì •ì±…ì„ ìœ„í•œ ê¸°ì¤€ì¼ ê³„ì‚°
            cutoff_date_int = int((target_date - timedelta(days=30)).strftime("%Y%m%d"))
            current_date_int = int(file_date_str)
        except ValueError:
            logger.error(f"âŒ ë‚ ì§œ í˜•ì‹ ì˜¤ë¥˜: {file_date_str} (YYYYMMDD í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤)")
            return

        logger.info(f"ğŸ”„ [{sns_name} | {category}] ê²€ì¦ ì™„ë£Œ. ë°ì´í„° ë¶„ì„ ì‹œì‘ (ê¸°ì¤€ì¼: {file_date_str})")

        # 3. DB ì •ë¦¬ (30ì¼ ì´ˆê³¼ ë°ì´í„° ì‚­ì œ ë° ë™ì¼ ë‚ ì§œ ë°ì´í„° êµì²´)
        try:
            # ì˜¤ë˜ëœ ë°ì´í„° ì‚­ì œ ($lt: Less Than)
            self.vector_service.delete_by_metadata(filter={
                "$and": [
                    {"sns": sns_name},
                    {"category": category},
                    {"timestamp": {"$lt": cutoff_date_int}}
                ]
            })
            # ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ ì˜¤ëŠ˜ ë‚ ì§œ ë°ì´í„° ì‚­ì œ
            self.vector_service.delete_by_metadata(filter={
                "$and": [
                    {"sns": sns_name},
                    {"category": category},
                    {"timestamp": current_date_int}
                ]
            })
        except Exception as e:
            logger.debug(f"â„¹ï¸ DB ì •ë¦¬ ì¤‘ ì°¸ê³ ì‚¬í•­: {e}")

        # 4. CSV ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
        try:
            # ì†Œë¬¸ì keyword, frequency ì»¬ëŸ¼ ëŒ€ì‘
            df = pd.read_csv(file_path, encoding='utf-8-sig')
            df.columns = [col.strip().lower() for col in df.columns]
        except Exception as e:
            logger.error(f"âŒ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
            return

        if 'keyword' not in df.columns or 'frequency' not in df.columns:
            logger.error(f"âŒ í•„ìˆ˜ ì»¬ëŸ¼(keyword, frequency) ëˆ„ë½. í˜„ì¬ ì»¬ëŸ¼: {list(df.columns)}")
            return

        # 5. ë°ì´í„° ì ì¬ ì¤€ë¹„ (ë¹ˆë„ìˆ˜ 3 ì´ìƒë§Œ)
        documents, metadatas, ids = [], [], []
        save_time = datetime.now().strftime("%Y-%m-%d %H:%M")

        for _, row in df.iterrows():
            kw = str(row['keyword']).strip()
            count = int(row['frequency'])
            
            if count >= 3:
                # ìì—°ì–´ ë¬¸ì„œ ìƒì„± (Rank ì œì™¸)
                doc_text = f"[{sns_name} - {category}] '{kw}' ì–¸ê¸‰ ë¹ˆë„: {count}íšŒ (ê¸°ì¤€ì¼: {file_date_str})"
                
                documents.append(doc_text)
                metadatas.append({
                    "sns": sns_name,
                    "category": category,
                    "keyword": kw,
                    "count": count,
                    "timestamp": current_date_int,
                    "updated_at": save_time
                })
                # ê³ ìœ  ID ìƒì„± (SNS_ì¹´í…Œê³ ë¦¬_ë‚ ì§œ_í‚¤ì›Œë“œ)
                ids.append(f"{sns_name}_{category}_{current_date_int}_{kw}")

        # 6. ìµœì¢… Vector DB ì ì¬
        if ids:
            self.vector_service.add_documents(documents=documents, metadatas=metadatas, ids=ids)
            logger.info(f"âœ… ë™ê¸°í™” ì™„ë£Œ: {len(ids)}ê°œì˜ ìœ íš¨ í‚¤ì›Œë“œê°€ DBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            logger.warning(f"âš ï¸ {base_name}ì— ë¹ˆë„ìˆ˜ 3 ì´ìƒì˜ ì ì¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")