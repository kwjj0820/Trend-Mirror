import streamlit as st
import json
import httpx
import uuid
import os
BACKEND_URL = os.getenv("BACKEND_URL","http://localhost:8000")

st.set_page_config(
    page_title ="TREND MIRROR",
    page_icon = "ğŸ“ˆ",
    layout = "wide"
)

if "session_id" not in st.session_state:
    st.session_state.session_id  = str(uuid.uuid4())

if "messages" not in st.session_state:
    st.session_state.messages = []


st.title("TREND_MIRROR")
st.markdown("íŠ¸ë Œë“œ ë¶„ì„ ë§ˆì¼€íŒ… report")
with st.sidebar:
    st.header("ì„¤ì •")
    if st.button("ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.session_state.session_id = str(uuid.uuid4())
        st.rerun() #ì´ˆê¸°í™”
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

def response_generator(prompt, session_id):
    try:
        with httpx.stream(
            "POST",
            f"{BACKEND_URL}/agent/chat/stream",
            json={
                "query" : prompt,
                "session_id":session_id
            },
            timeout=None
        ) as response:
            if response.status_code != 200:
                yield f"ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì˜€ìŠµë‹ˆë‹¤ (ìƒíƒœì½”ë“œ: {response.status_code})"
                return
            status = st.status("trend mirror ì—ì´ì „íŠ¸ê°€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤....")

            is_answering = False
            
            for line in response.iter_lines():
                if line.startswith("data: "):
                    data_str = line[len("data: "):].strip()
                
                    if data_str == "[DONE]":
                        break
                    try:
                        event = json.loads(data_str)
                        if "error" in event:
                            yield f"\n\n error : {event['error']}"
                        
                        if "log" in event:
                            status.write(event['log'])
                            continue
                        if "answer" in event and event["answer"]:
                            if not is_answering:
                                status.update(label="ë¶„ì„ ì™„ë£Œ", state="complete", expanded=False)
                                is_answering=True
                            
                            yield event["answer"] # ë°ì´í„° í•œë©ì´ì”© ë°–ìœ¼ë¡œ
                    except json.JSONDecodeError:
                        continue

            if not is_answering:
                status.update(label="ì‘ì—… ì™„ë£Œ", state="complete", expanded=False)
            
    except Exception as e:
            yield f"ì—°ê²° ì˜¤ë¥˜:{str(e)}"

if prompt := st.chat_input("ë¶„ì„í•˜ê³  ì‹¶ì€ íŠ¸ë Œë“œ ì£¼ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."):

    # 1. ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¨¼ì € í™”ë©´ì— ê·¸ë¦¬ê¸°
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # 2. AI ë‹µë³€ ì˜ì—­ ê·¸ë¦¬ê¸°
    with st.chat_message("assistant"):
        # [í•µì‹¬] response_generatorê°€ yieldí•˜ëŠ” ê¸€ìë“¤ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ í™”ë©´ì— ì”€
        full_response = st.write_stream(
            response_generator(prompt, st.session_state.session_id)
        )

    # 3. ë‹µë³€ì´ ë‹¤ ì™„ì„±ë˜ë©´ ì €ì¥ì†Œì— ê¸°ë¡
    st.session_state.messages.append({
        "role": "assistant",
        "content": full_response
    })

# Footer information
st.markdown("---")
st.caption("Powered by Upstage Solar LLM & LangGraph")
                                